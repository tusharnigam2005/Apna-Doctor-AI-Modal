# Apna-Doctor-AI-Modal
This Project aims to develop an AI-based multimodal assistant capable of understanding and responding to user queries through audio or image inputs. The assistant leverages state-of-the-art models to interpret multimodal data and delivers accurate, informative responses both in text and spoken audio formats.
